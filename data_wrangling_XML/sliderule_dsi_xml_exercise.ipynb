{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XML example and exercise\n",
    "****\n",
    "+ study examples of accessing nodes in XML tree structure  \n",
    "+ work on exercise to be completed and submitted\n",
    "****\n",
    "+ reference: https://docs.python.org/2.7/library/xml.etree.elementtree.html\n",
    "+ data source: http://www.dbis.informatik.uni-goettingen.de/Mondial\n",
    "****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from xml.etree import ElementTree as ET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XML example\n",
    "\n",
    "+ for details about tree traversal and iterators, see https://docs.python.org/2.7/library/xml.etree.elementtree.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "document_tree = ET.parse( './data/mondial_database_less.xml' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Albania\n",
      "Greece\n",
      "Macedonia\n",
      "Serbia\n",
      "Montenegro\n",
      "Kosovo\n",
      "Andorra\n"
     ]
    }
   ],
   "source": [
    "# print names of all countries\n",
    "for child in document_tree.getroot():\n",
    "    print (child.find('name').text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Albania:\n",
      "Tirana, Shkodër, Durrës, Vlorë, Elbasan, Korçë\n",
      "* Greece:\n",
      "Komotini, Kavala, Athina, Peiraias, Peristeri, Acharnes, Patra, Kozani, Kerkyra, Ioannina, Thessaloniki, Iraklio, Chania, Ermoupoli, Rhodes, Tripoli, Lamia, Chalkida, Larissa, Volos, Mytilini, Karyes\n",
      "* Macedonia:\n",
      "Skopje, Kumanovo\n",
      "* Serbia:\n",
      "Beograd, Novi Sad, Niš\n",
      "* Montenegro:\n",
      "Podgorica\n",
      "* Kosovo:\n",
      "Prishtine\n",
      "* Andorra:\n",
      "Andorra la Vella\n"
     ]
    }
   ],
   "source": [
    "# print names of all countries and their cities\n",
    "for element in document_tree.iterfind('country'):\n",
    "    print ('* ' + element.find('name').text + ':')\n",
    "    capitals_string = ''\n",
    "    for subelement in element.getiterator('city'):\n",
    "        capitals_string += subelement.find('name').text + ', '\n",
    "    print (capitals_string[:-2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****\n",
    "## XML exercise\n",
    "\n",
    "Using data in 'data/mondial_database.xml', the examples above, and refering to https://docs.python.org/2.7/library/xml.etree.elementtree.html, find\n",
    "\n",
    "1. 10 countries with the lowest infant mortality rates\n",
    "2. 10 cities with the largest population\n",
    "3. 10 ethnic groups with the largest overall populations (sum of best/latest estimates over all countries)\n",
    "4. name and country of a) longest river, b) largest lake and c) airport at highest elevation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "document = ET.parse( './data/mondial_database.xml' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10 Countries with the lowest infant mortality rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Monaco            1.81\n",
       "Japan             2.13\n",
       "Norway            2.48\n",
       "Bermuda           2.48\n",
       "Singapore         2.53\n",
       "Sweden            2.60\n",
       "Czech Republic    2.63\n",
       "Hong Kong         2.73\n",
       "Macao             3.13\n",
       "Iceland           3.15\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First, get to the root\n",
    "root = document.getroot()\n",
    "\n",
    "# Loop over all the countries\n",
    "country_by_infant_mortality = {}\n",
    "for cntr in root.iterfind('country'):\n",
    "    # Get the infant mortality in each country\n",
    "    name = cntr.find('name').text\n",
    "    try:\n",
    "        country_by_infant_mortality[name] = float(cntr.find('infant_mortality').text)\n",
    "    except:\n",
    "        country_by_infant_mortality[name] = np.nan\n",
    "    \n",
    "# Convert to series\n",
    "ser1 = pd.Series(country_by_infant_mortality)\n",
    "\n",
    "# Compute lowest 10\n",
    "ser1.sort_values().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10 Cities with the largest populations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seoul              9708483.0\n",
       "Al Qahirah         8471859.0\n",
       "Bangkok            7506700.0\n",
       "Hong Kong          7055071.0\n",
       "Ho Chi Minh        5968384.0\n",
       "Singapore          5076700.0\n",
       "Al Iskandariyah    4123869.0\n",
       "New Taipei         3939305.0\n",
       "Busan              3403135.0\n",
       "Pyongyang          3255288.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loop over all the countries\n",
    "\n",
    "cities_by_population = {}\n",
    "for cntr in root.iterfind('country'):\n",
    "    # Get the cities\n",
    "    for city in cntr.findall('city'):\n",
    "        # Get the latest population\n",
    "        name = city.find('name').text\n",
    "        try:\n",
    "            cities_by_population[name] = float(city.findall('population')[-1].text)\n",
    "        except:\n",
    "            cities_by_population[name] = np.nan\n",
    "            \n",
    "# Convert to series\n",
    "ser2 = pd.Series(cities_by_population)\n",
    "\n",
    "# Compute top 10\n",
    "ser2.sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10 Ethnic groups with largest populations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Han Chinese', 124505880000.0),\n",
       " ('Indo-Aryan', 87181558344.0),\n",
       " ('European', 49487221971.96),\n",
       " ('African', 31832512036.9),\n",
       " ('Dravidian', 30271374425.0),\n",
       " ('Mestizo', 15773435493.7),\n",
       " ('Bengali', 14677691672.0),\n",
       " ('Russian', 13185699607.699999),\n",
       " ('Japanese', 12653421200.0),\n",
       " ('Malay', 12199355037.4)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "ethnic_groups_by_population = Counter()\n",
    "\n",
    "for cntr in root.iterfind('country'):\n",
    "    # Get the population of the country (the latest record)\n",
    "    pop = float(cntr.findall('population')[-1].text)\n",
    "    \n",
    "    # Now loop over all the ethnic groups\n",
    "    list_of_eth = cntr.findall('ethnicgroup')\n",
    "    if (len(list_of_eth) > 0):\n",
    "        for eth in list_of_eth:\n",
    "            # Get precentage\n",
    "            perc = eth.attrib['percentage']\n",
    "            ethnic_groups_by_population[eth.text] += pop * float(perc)\n",
    "\n",
    "# Use Counter's most common method\n",
    "ethnic_groups_by_population.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Name & Country of a) longest river, b) largest lake, c) airport at highest elevation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# First let's get a list of all countries, rivers, lakes and airports\n",
    "countries = root.findall('country')\n",
    "rivers = root.findall('river')\n",
    "lakes = root.findall('lake')\n",
    "airports = root.findall('airport')\n",
    "\n",
    "# Names of countries will be macthed with their abbreviations (or car codes)\n",
    "cntr_abbrv = {}\n",
    "for cntr in countries:\n",
    "    full_name = cntr.find('name').text\n",
    "    abbrv = cntr.attrib['car_code']\n",
    "    cntr_abbrv[abbrv] = full_name\n",
    "\n",
    "# Convert into dataframe to be merged later\n",
    "df_abbrv = pd.Series(cntr_abbrv).to_frame().reset_index()\n",
    "df_abbrv.index = range(len(cntr_abbrv))\n",
    "df_abbrv.columns = ['abbrv_country', 'country_name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Longest River by Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>river_name</th>\n",
       "      <th>river_length</th>\n",
       "      <th>country_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>Amazonas</td>\n",
       "      <td>6448.0</td>\n",
       "      <td>Peru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>Amazonas</td>\n",
       "      <td>6448.0</td>\n",
       "      <td>Colombia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>Amazonas</td>\n",
       "      <td>6448.0</td>\n",
       "      <td>Brazil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>Jangtse</td>\n",
       "      <td>6380.0</td>\n",
       "      <td>China</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>Hwangho</td>\n",
       "      <td>4845.0</td>\n",
       "      <td>China</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    river_name  river_length country_name\n",
       "310   Amazonas        6448.0         Peru\n",
       "299   Amazonas        6448.0     Colombia\n",
       "302   Amazonas        6448.0       Brazil\n",
       "226    Jangtse        6380.0        China\n",
       "225    Hwangho        4845.0        China"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Longest river\n",
    "longest_rivers_by_country = defaultdict(list) # Initiate\n",
    "for river in rivers:\n",
    "    cntrs = river.attrib['country'].split() # Name(s) of the country where the river is located\n",
    "    river_name = river.find('name').text # Name of river\n",
    "    # Length of river\n",
    "    try:\n",
    "        length = float(river.find('length').text)\n",
    "    except:\n",
    "        length = np.nan\n",
    "    \n",
    "    # Add to the dictionary\n",
    "    for cntr in cntrs:\n",
    "        # Store in the dictionary\n",
    "        longest_rivers_by_country['river_name'].append(river_name)\n",
    "        longest_rivers_by_country['abbrv_country'].append(cntr)\n",
    "        longest_rivers_by_country['river_length'].append(length)\n",
    "\n",
    "# Now convert into pandas dataframe\n",
    "df1 = pd.DataFrame(longest_rivers_by_country)\n",
    "\n",
    "# Merge with abbreviations\n",
    "df1 = df1.merge(df_abbrv, on = \"abbrv_country\")\n",
    "\n",
    "# Now sort by river length and print\n",
    "df1.sort_values('river_length', ascending=False)[['river_name', 'river_length', 'country_name']].head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country_name\n",
       "Brazil      6448.0\n",
       "Peru        6448.0\n",
       "Colombia    6448.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can also extract the longest river countries by groupby\n",
    "grps = df1.groupby(['river_name', 'country_name'])\n",
    "df2 = grps.apply(lambda x: np.max(x.river_length)).sort_values(ascending = False)\n",
    "df2[df2.index[0][0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, the longest river is the Amazon river, which run through Brazil, Peru and Colombia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Largest lake by Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lake_name</th>\n",
       "      <th>lake_area</th>\n",
       "      <th>country_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Caspian Sea</td>\n",
       "      <td>386400.0</td>\n",
       "      <td>Russia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>Caspian Sea</td>\n",
       "      <td>386400.0</td>\n",
       "      <td>Iran</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>Caspian Sea</td>\n",
       "      <td>386400.0</td>\n",
       "      <td>Azerbaijan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>Caspian Sea</td>\n",
       "      <td>386400.0</td>\n",
       "      <td>Kazakhstan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>Caspian Sea</td>\n",
       "      <td>386400.0</td>\n",
       "      <td>Turkmenistan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>Lake Superior</td>\n",
       "      <td>82103.0</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         lake_name  lake_area  country_name\n",
       "56     Caspian Sea   386400.0        Russia\n",
       "72     Caspian Sea   386400.0          Iran\n",
       "73     Caspian Sea   386400.0    Azerbaijan\n",
       "74     Caspian Sea   386400.0    Kazakhstan\n",
       "77     Caspian Sea   386400.0  Turkmenistan\n",
       "148  Lake Superior    82103.0        Canada"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Largest lake\n",
    "largest_lakes_by_country = defaultdict(list) # Initiate\n",
    "for lake in lakes:\n",
    "    cntrs = lake.attrib['country'].split() # Name(s) of the country where the lake is located\n",
    "    lake_name = lake.find('name').text # Name of lake\n",
    "    # Length of river\n",
    "    try:\n",
    "        length = float(lake.find('area').text)\n",
    "    except:\n",
    "        length = np.nan\n",
    "    \n",
    "    # Add to the dictionary\n",
    "    for cntr in cntrs:\n",
    "        # Store in the dictionary\n",
    "        largest_lakes_by_country['lake_name'].append(lake_name)\n",
    "        largest_lakes_by_country['abbrv_country'].append(cntr)\n",
    "        largest_lakes_by_country['lake_area'].append(length)\n",
    "\n",
    "# Now convert into pandas dataframe\n",
    "df3 = pd.DataFrame(largest_lakes_by_country)\n",
    "\n",
    "# Merge with abbreviations\n",
    "df3 = df3.merge(df_abbrv, on = \"abbrv_country\")\n",
    "\n",
    "# Now sort by river length and print\n",
    "df3.sort_values('lake_area', ascending=False)[['lake_name', 'lake_area', 'country_name']].head(6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country_name\n",
       "Kazakhstan      386400.0\n",
       "Iran            386400.0\n",
       "Azerbaijan      386400.0\n",
       "Russia          386400.0\n",
       "Turkmenistan    386400.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now by groupby\n",
    "grps = df3.groupby(['lake_name', 'country_name'])\n",
    "df4 = grps.apply(lambda x: np.max(x.lake_area)).sort_values(ascending = False)\n",
    "df4[df4.index[0][0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, the largest lake is the Caspian Sea, which is located in the above countries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Airport with highest elevation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airport_name</th>\n",
       "      <th>elevation</th>\n",
       "      <th>country_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>El Alto Intl</td>\n",
       "      <td>4063.0</td>\n",
       "      <td>Bolivia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>Lhasa-Gonggar</td>\n",
       "      <td>4005.0</td>\n",
       "      <td>China</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>Yushu Batang</td>\n",
       "      <td>3963.0</td>\n",
       "      <td>China</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>813</th>\n",
       "      <td>Juliaca</td>\n",
       "      <td>3827.0</td>\n",
       "      <td>Peru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>815</th>\n",
       "      <td>Teniente Alejandro Velasco Astete Intl</td>\n",
       "      <td>3311.0</td>\n",
       "      <td>Peru</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               airport_name  elevation country_name\n",
       "80                             El Alto Intl     4063.0      Bolivia\n",
       "219                           Lhasa-Gonggar     4005.0        China\n",
       "241                            Yushu Batang     3963.0        China\n",
       "813                                 Juliaca     3827.0         Peru\n",
       "815  Teniente Alejandro Velasco Astete Intl     3311.0         Peru"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Highest elevation airport\n",
    "airports_by_country = defaultdict(list) # Initiate\n",
    "for airport in airports:\n",
    "    cntr = airport.attrib['country'] # Name of the country where the lake is located\n",
    "    airport_name = airport.find('name').text\n",
    "    try:\n",
    "        elevation = float(airport.find('elevation').text)\n",
    "    except:\n",
    "        elevation = np.nan\n",
    "    \n",
    "    # Add to dictionary\n",
    "    airports_by_country['airport_name'].append(airport_name)\n",
    "    airports_by_country['abbrv_country'].append(cntr)\n",
    "    airports_by_country['elevation'].append(elevation)\n",
    "    \n",
    "# Now convert into pandas dataframe\n",
    "df5 = pd.DataFrame(airports_by_country)\n",
    "\n",
    "# Merge with abbreviations\n",
    "df5 = df5.merge(df_abbrv, on = \"abbrv_country\")\n",
    "\n",
    "# Now sort by river length and print\n",
    "df5.sort_values('elevation', ascending=False)[['airport_name', 'elevation', 'country_name']].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, the highest elevation airport is El Alto Intl located at Bolivia."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
